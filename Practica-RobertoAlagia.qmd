---
format: html
editor: visual
  markdown: 
    wrap: 72
---

Vasmos a cargar el dataset de AirBnB descargado de [aquí](https://public.opendatasoft.com/explore/dataset/airbnb-listings/export/?disjunctive.host_verifications&disjunctive.amenities&disjunctive.features&q=Madrid&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQ09VTlQiLCJ5QXhpcyI6Imhvc3RfbGlzdGluZ3NfY291bnQiLCJzY2llbnRpZmljRGlzcGxheSI6dHJ1ZSwiY29sb3IiOiJyYW5nZS1jdXN0b20ifV0sInhBeGlzIjoiY2l0eSIsIm1heHBvaW50cyI6IiIsInRpbWVzY2FsZSI6IiIsInNvcnQiOiIiLCJzZXJpZXNCcmVha2Rvd24iOiJyb29tX3R5cGUiLCJjb25maWciOnsiZGF0YXNldCI6ImFpcmJuYi1saXN0aW5ncyIsIm9wdGlvbnMiOnsiZGlzanVuY3RpdmUuaG9zdF92ZXJpZmljYXRpb25zIjp0cnVlLCJkaXNqdW5jdGl2ZS5hbWVuaXRpZXMiOnRydWUsImRpc2p1bmN0aXZlLmZlYXR1cmVzIjp0cnVlfX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=16,41.38377,2.15774&basemap=jawg.streets)

![](descargar.png)

```{r}
airbnb<-read.csv('data/airbnb-listings.csv',sep = ';')
options(repr.plot.height=4,repr.plot.width=6,repr.plot.res = 300)
```

1.  Vamos a quedarnos con las columnas de mayor interés: 'City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude' Nos quedarmos solo con las entradas de Madrid para Room.Type=="Entire home/apt" y cuyo barrio (Neighbourhood) no está vacio '' Podemos eliminar las siguientes columnas que ya no son necesarias: "Room.Type",'City' Llama a nuevo dataframe df_madrid.

```{r}
airbnb <- airbnb[,c('City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude')]
df_madrid <- airbnb[which(airbnb$City == 'Madrid'),]
df_madrid <- df_madrid[which(df_madrid$Room.Type=="Entire home/apt"),]
df_madrid <- df_madrid[which(df_madrid$Neighbourhood!=""),]
df_madrid <- subset(df_madrid,select = -c(Room.Type,City))
```

```{r}
#head(df_madrid)
str(df_madrid)
```

------------------------------------------------------------------------

2.  Crea una nueva columna llamada Square.Meters a partir de Square.Feet. Recuerda que un pie cuadrado son 0.092903 metros cuadrados.

```{r}
pie2= 0.092903
df_madrid['Square.Meters'] <- df_madrid$Square.Feet*pie2
```

```{r}
#dim(df_madrid)
tail(df_madrid)
```

------------------------------------------------------------------------

3.  ¿Que porcentaje de los apartamentos no muestran los metros cuadrados? Es decir, ¿cuantos tienen NA en Square.Meters?

```{r}
#c(length(df_madrid$Square.Meters[is.na(df_madrid$Square.Meters)]),
#  length(df_madrid$Square.Meters[!is.na(df_madrid$Square.Meters)]))
porc_m2_na <- length(df_madrid$Square.Meters[is.na(df_madrid$Square.Meters)])/(length(df_madrid$Square.Meters[is.na(df_madrid$Square.Meters)])+length(df_madrid$Square.Meters[!is.na(df_madrid$Square.Meters)]))
porc_m2_na
```

------------------------------------------------------------------------

4.  De todos los apartamentos que tienen un valor de metros cuadrados diferente de NA ¿Que porcentaje de los apartamentos tienen 0 metros cuadrados?

```{r}
#dim(df_madrid)
porc_m2_0 <- nrow(df_madrid[which(df_madrid$Square.Meters==0),])/length(df_madrid$Square.Meters[!is.na(df_madrid$Square.Meters)])
porc_m2_0
```

------------------------------------------------------------------------

5.  Reemplazar todos los 0m\^2 por NA

```{r}
df_madrid[which(df_madrid$Square.Meters==0),] <- NA
df_madrid[which(df_madrid$Square.Meters==0),]
```

------------------------------------------------------------------------

Hay muchos NAs, vamos a intentar crear un modelo que nos prediga cuantos son los metros cuadrados en función del resto de variables para tratar de rellenar esos NA. Pero **antes de crear el modelo** vamos a hacer: \* pintar el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más. \* crear una variable sintética nueva basada en la similitud entre barrios que usaremos en nuestro modelo.

6.  Pinta el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más

```{r}
library(tidyverse)
```

```{r}
ggplot(df_madrid, aes(x=Square.Meters))+geom_histogram(position = 'identity', alpha=0.5, bins=10)
```

------------------------------------------------------------------------

7.  Asigna el valor NA a la columna Square.Meters de los apartamentos que tengan menos de 20 m\^2

```{r}
df_madrid[which(df_madrid$Square.Meters<20),] <- NA
df_madrid[which(df_madrid$Square.Meters<20),]
```

------------------------------------------------------------------------

8.  Existen varios Barrios que todas sus entradas de Square.Meters son NA, vamos a eliminar del dataset todos los pisos que pertenecen a estos barrios.

    ```{r}
    df_madrid |> group_by(Neighbourhood) |> summarise(son_na=sum(is.na(Square.Meters)),muestras=n()) -> neighbourhood_empty
    neighbourhood_empty <- neighbourhood_empty[neighbourhood_empty$son_na==neighbourhood_empty$muestras,]
    df_madrid_clean <- filter(df_madrid, !df_madrid$Neighbourhood %in% neighbourhood_empty$Neighbourhood)
    ```

    ------------------------------------------------------------------------

9.  ¿Tienen todos los barrios los mismos metros cuadrados de media? ¿Con que test lo comprobarías?

    ```{r}
    #Medimos el pvalue con shapiro para todos los barrios que tengan al menos 3 muestras.
    for (v in levels(df_madrid_clean$Neighbourhood)){
        if(length(na.omit((df_madrid_clean$Square.Meters[df_madrid_clean$Neighbourhood==v]))) > 2)
          print(paste("Neighbourhood:",v,"pvalue,",
                    shapiro.test(df_madrid_clean$Square.Meters[df_madrid_clean$Neighbourhood==v])$p.value))
    }
    #Nos da que las distribuciones de algunos de los barrios son diferentes a una normal por lo que aplicamos Kruskal. ¿El hecho de tener barrios con tan pocas muestras, ya sería suficiente para escoger Kruskal como test de análisis? 
    ```

    ```{r}
    #ggplot(df_madrid_clean, aes(y=Square.Meters, x= df_madrid_clean$Neighbourhood, color = df_madrid_clean$Neighbourhood))+geom_boxplot()

    df_madrid_clean$Neighbourhood <- as.factor(df_madrid_clean$Neighbourhood)
    #summary(aov( Square.Meters ~ Neighbourhood, data=df_madrid_clean))
    kruskal.test( Square.Meters ~ Neighbourhood, data = df_madrid_clean)

    #Usando Test de anova -Kruskal. Ya que no se cumple la normalidad de los datos- al tener un valor de p muy bajo, indica que se descarta la hipótesis nula. Dando a entender que no todos los grupos tienen la misma media. Lo mismo se podía observar si se ejecuta el boxplot
    ```

    ------------------------------------------------------------------------

10. Vamos a agrupar los barrios por metros cuadrados. Podemos usar una matriz de similaridad de Tukey. Muestra como de similares o diferentes son los barrios si nos fijámos únicamente en los metros cuadrados de los pisos. ¿Como se diferencia la media del Barrio A al Barrio B? (Es decir, cual sería el pvalor suponiendo una H0 en la que las medias son iguales)

    ```{r}
    tky<-TukeyHSD(aov( Square.Meters ~ Neighbourhood, data=df_madrid_clean))
    #tky
    ```

    ```{r}
    library(tidyr)
    tky.result<-data.frame(tky$Neighbourhood)
    cn <-sort(unique(df_madrid_clean$Neighbourhood))
    resm <- matrix(NA, length(cn),length(cn))
    rownames(resm) <- cn
    colnames(resm) <- cn
    resm[lower.tri(resm) ] <- round(tky.result$p.adj,4)
    resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)] 
    diag(resm) <- 1
    library(ggplot2)
    library(reshape2)
    dfResm <- melt(resm)
    ggplot(dfResm, aes(x=Var1, y=Var2, fill=value))+
      geom_tile(colour = "black")+
      geom_text(aes(label=paste(round(value*100,0),"%")),size = 1) +
      scale_fill_gradient(low = "white",high = "steelblue")+
      ylab("Class")+xlab("Class")+theme_bw()+
      theme(axis.text.x = element_text(angle = 90, hjust = 0.01),legend.position="none")
    ```

------------------------------------------------------------------------

11. En el punto anterior has creado una matriz de p-valores que indica como de parecidos son dos barrios. Si su pvalor es alto significa que los barrios son diferentes, si es bajo significa que los barrios se parecen. Esta matriz la podemos usar como matriz de distancia si restamos el pvalor a 1. Es decir si usamos como distancia 1-pvalor. De esta forma barrios con un pvalor alto tendrán una distancia mayor que aquellos con un pvalor bajo. Usando esta última métrica como matriz de distancias dibuja un dendrograma de los diferentes barrios.

    ```{r}
    dfResm$value <- 1-dfResm$value
    d <- dist(as.matrix(dfResm),method = "euclidean")
    hc <- hclust(d,method="complete")
    hcd <- as.dendrogram(hc)
    par(cex=0.3)
    plot(hcd)
    ```

------------------------------------------------------------------------

10. ¿Que punto de corte sería el aconsejable?, ¿cuantos clusters aparecen?

```{r}
library(dendextend)
labels(hcd)<-dfResm$Var1[labels(hcd)]
hcd<-set(hcd,"labels_cex", 0.45) 
plot(color_branches(hcd,h=1),cex=0)
abline(h=1,col="red")
#Aparecen 3 clusters y se decide cortar en 1 aprovechando la estabilidad de las lineas divisorias. Antes que empiecen a bifurcar de forma recurrente.
```

------------------------------------------------------------------------

11. Vamos a crear una nueva columna en el dataframe df_madrid con un nuevo identificador marcado por los clusters obtenidos. Esta columna la llamaremos neighb_id

```{r}
table(dfResm$Var1,
      cutree_1h.dendrogram(hcd,h=1))
```

```{r}
#Añadir columna nueva con id del cluster
df_madrid_clean$neighb_id <- cutree_1h.dendrogram(hcd,h=1)[df_madrid_clean$Neighbourhood]
```

------------------------------------------------------------------------

12. Vamos a crear dos grupos, uno test y otro train.

```{r}
set.seed(3)
num_train=round(0.7*nrow(df_madrid_clean))
train_ind<-sample(1:nrow(df_madrid_clean),size = num_train)

df_madrid_clean.train=df_madrid_clean[train_ind,]
df_madrid_clean.test =df_madrid_clean[-train_ind,]
summary(df_madrid_clean.train)
summary(df_madrid_clean.test)
```

------------------------------------------------------------------------

13. Tratamos de predecir los metros cuadrados en función del resto de columnas del dataframe.

```{r}
#model <- lm(df_madrid_clean.train, formula=Square.Meters~.-Neighbourhood-Square.Feet-Latitude-Longitude-Beds-Review.Scores.Rating-Extra.People, na.action = na.omit) -> De esta manera da error porque aunque borre el campo 'Neighbourhood', diría que en el interior de R al ejecutar primero lee completo todos los campos y se queda en memoria para cuando ejecuta el predict (?)
model <- lm(df_madrid_clean.train, formula=Square.Meters~Accommodates+Bathrooms+Bedrooms+Price+neighb_id, na.action = na.omit)
summary(model)

```

```{r}
df_madrid_clean.train$sqrm_est<-predict(model,df_madrid_clean.train)
paste("Error cuadrático medio",sqrt(mean((df_madrid_clean.train$Square.Meters-df_madrid_clean.train$sqrm_est)^2,na.rm = TRUE)))
```

------------------------------------------------------------------------

14. Evaluar la calidad de vuestro modelo

```{r}
df_madrid_clean.test$sqrm_est<-predict(model,df_madrid_clean.test)
paste("Error cuadrático medio",sqrt(mean((df_madrid_clean.test$Square.Meters-df_madrid_clean.test$sqrm_est)^2,na.rm = TRUE)))

```

```{r}
hist(df_madrid_clean.test$Square.Meters-df_madrid_clean.test$sqrm_est,20)
qqnorm(df_madrid_clean.test$Square.Meters-df_madrid_clean.test$sqrm_est)
qqline(df_madrid_clean.test$Square.Meters-df_madrid_clean.test$sqrm_est, col = 'orange', lwd =2)
```

```{r}
res <- (df_madrid_clean.test$Square.Meters-df_madrid_clean.test$sqrm_est)
shapiro.test(res[sample(1:length(res),1000)])

#Los residuos siguen una distribución normal
```

------------------------------------------------------------------------

15. Si tuvieramos un anuncio de un apartamento para 6 personas (Accommodates), con 1 baño, con un precio de 80€/noche y 3 habitaciones en el barrio de Sol, con 3 camas y un review de 80. ¿Cuantos metros cuadrados tendría? Si tu modelo necesita algúna variable adicional puedes inventartela dentro del rango de valores del dataset. ¿Como varía sus metros cuadrados con cada habitación adicional?

```{r}
print("Predicción de metros cuadrados usando el método predict():")
predict(model,data.frame(Accommodates=6,Bathrooms=1,Bedrooms=3,Price=80,Neighbouhood= "Sol",Beds=3,Review.Scores.Rating=80, neighb_id=3))

print("Predicción de metros cuadrados para 2 habitaciones:")
predict(model,data.frame(Accommodates=6,Bathrooms=1,Bedrooms=2,Price=80,Neighbouhood= "Sol",Beds=3,Review.Scores.Rating=80, neighb_id=3))

print("Predicción de metros cuadrados para 2 habitaciones:")
predict(model,data.frame(Accommodates=6,Bathrooms=1,Bedrooms=4,Price=80,Neighbouhood= "Sol",Beds=3,Review.Scores.Rating=80, neighb_id=3))

#Para el caso descrito tendría 74.26657   m^2
#Si se quita 1 habitación -> 69.9518   m^2
#Si se añade 1 habitación -> 78.58135  m^2
#En otras palabras aumenta o disminuye lo que define el modelo en el apartado 13. Bedrooms 4.31478 
```

------------------------------------------------------------------------

16. Rellenar los Square.Meters con valor NA con el estimado con el modelo anterior.

```{r}
df_madrid_clean$Square.Meters[is.na(df_madrid_clean$Square.Meters)] <- predict(model,df_madrid_clean)[is.na(df_madrid_clean$Square.Meters)]
```

------------------------------------------------------------------------

17. Usar PCA para encontrar el apartamento más cercano a uno dado. Este algoritmo nos ayudaría a dado un apartamento que el algoritmo nos devolvería los 5 apartamentos más similares.

Crearemos una función tal que le pasemos un apartamento con los siguientes datos: \* Accommodates \* Bathrooms \* Bedrooms \* Beds \* Price \* Guests.Included \* Extra.People \* Review.Scores.Rating \* Latitude \* Longitude \* Square.Meters

y nos devuelva los 5 más similares de:

```{r}
ap_matrix <- model.matrix(~Accommodates+ Bathrooms+ Bedrooms+ Beds+ Price+ Guests.Included+ Extra.People+ Review.Scores.Rating+ Latitude+ Longitude+ Square.Meters, data = df_madrid_clean)
pr_ap<-prcomp(ap_matrix,center = TRUE)
summary(pr_ap)
```

```{r}
number_of_pca_components<-3

orig_ap <- model.matrix(~Accommodates+ Bathrooms+ Bedrooms+ Beds+ Price+ Guests.Included+ Extra.People+ Review.Scores.Rating+ Latitude+ Longitude+ Square.Meters, data = data.frame(Accommodates=3 , Bathrooms= 2, Bedrooms= 3, Beds= 3, Price= 120, Guests.Included= 3, Extra.People= 25, Review.Scores.Rating= 80, Latitude= 40.45529, Longitude= -3.701512, Square.Meters= 60))
```

```{r}
busqueda_pisos<-function(pca_result=pr_ap,data=df_madrid_clean,pca_components= number_of_pca_components,apartamento=orig_ap){
  
    t_ap<-predict(pca_result,newdata= apartamento)
    t_ap<-matrix(t_ap[1:pca_components],nrow=1) 
    
    Apc<-pca_result$x[,1:pca_components]
    dist<-rep(NA,nrow(Apc))
      for (i in 1:nrow(Apc)){
        dist[i]<-sum((t_ap-Apc[i,])^2)
      }
    pisos_similares <- data[order(dist), ][1:5, ]
    return(pisos_similares)
}
```

```{r}
busqueda <- busqueda_pisos()
print(busqueda)
```

------------------------------------------------------------------------
